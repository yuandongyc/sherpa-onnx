# English-Resource-Processing 项目计划

## 项目概述
创建一个视频处理项目，功能包括：
1. **步骤1**: 视频转音频（转换为 WAV 格式）
2. **步骤2**: 使用 VAD + Whisper 进行长音频语音识别

## 项目结构
```
English-Resource-Processing/
├── package.json
├── config.js (配置文件)
├── scan-videos.js (扫描脚本)
├── batch-convert.js (批量转换脚本)
├── transcribe-audio.js (音频识别脚本)
├── video-converter/ (视频转换模块)
│   ├── src/
│   │   ├── converter.ts
│   │   └── index.ts
│   ├── package.json
│   ├── tsconfig.json
│   ├── README.md
│   └── README_CN.md
├── audio-transcriber/ (音频识别模块)
│   ├── src/
│   │   ├── transcriber.ts
│   │   └── index.ts
│   ├── package.json
│   ├── tsconfig.json
│   ├── README.md
│   └── README_CN.md
├── screenshot-scripts/ (截图脚本模块)
│   ├── copy-to-transcription2.js (复制转录文件并删除 ready)
│   └── generate-screenshots.js (生成视频截图)
├── extern/ (外部工具目录)
│   └── ffmpeg/ (FFmpeg 相关文件)
│       ├── ffmpeg.exe
│       └── ffprobe.exe
├── input/ (输入视频目录)
├── output/ (输出目录)
│   ├── audio/ (转换后的音频)
│   ├── transcription/ (识别结果)
│   ├── transcription2/ (处理后的识别结果，删除 ready 及其前面内容)
│   ├── screenshots/ (视频截图)
│   │   └── video2/ (video2 的截图目录)
│   └── video-list.json (视频列表配置)
├── 项目计划.md
└── README.md
```

## 实施步骤

### 1. 创建项目目录结构
- 创建项目根目录和子目录（包括 extern/ffmpeg/）

### 2. 复制 FFmpeg 文件到 extern/ffmpeg/
- 从 `D:\MyProjects\c_projects\sherpa-onnx\ffmpeg\bin\` 复制 ffmpeg.exe 和 ffprobe.exe

### 3. 创建 video-converter 模块
- 创建 video-converter/src/ 目录
- 创建 converter.ts 和 index.ts 文件
- 创建 tsconfig.json 和 package.json

### 4. 创建 config.js 配置文件
- FFmpeg 路径配置（指向 extern/ffmpeg/ffmpeg.exe）
- Whisper 模型路径 (使用现有的 all_models/sherpa-onnx-whisper-tiny.en)
- VAD 模型路径 (使用现有的 all_models/silero_vad.onnx)
- 输入输出目录配置

### 5. 创建扫描和转换脚本
- scan-videos.js: 扫描视频并生成配置文件
- batch-convert.js: 根据配置文件批量转换

### 6. 创建 audio-transcriber 模块
- 创建 audio-transcriber/src/ 目录
- 创建 transcriber.ts 和 index.ts 文件
- 创建 tsconfig.json 和 package.json

### 7. 创建音频识别脚本
- transcribe-audio.js: 批量识别 WAV 音频文件
- 使用 VAD + Whisper 进行语音识别
- 输出结果到 output/transcription/ 目录

### 8. 创建截图脚本模块
- 创建 screenshot-scripts/ 目录
- 创建 copy-to-transcription2.js: 复制转录文件并删除 "ready" 及其前面的内容
- 创建 generate-screenshots.js: 根据转录结果生成视频截图

### 9. 创建 README.md
- 项目说明
- 使用方法
- 依赖说明

## 技术要点
- 使用 `child_process.execSync` 调用 extern/ffmpeg/ 中的 FFmpeg
- 复用现有的 Whisper 和 VAD 模型
- 参考 `test_vad_with_non_streaming_asr_whisper_yd.js` 的识别逻辑
- 输出格式：分段结果（带时间戳）+ 完整文本
- extern 目录设计为可扩展，未来可添加其他工具
- **转录文件处理**: 自动识别并删除包含 "ready" 的 segment 及其前面的所有 segments
- **截图生成**: 根据转录结果的时间戳，使用 FFmpeg 生成视频截图
- **截图命名**: 使用 `screenshot_0001.jpg`, `screenshot_0002.jpg` 等格式命名

## 参考文件
- 长音频识别示例: `D:\MyProjects\c_projects\sherpa-onnx\nodejs-addon-examples\test_vad_with_non_streaming_asr_whisper_yd.js`
- 操作手册: `D:\MyProjects\c_projects\sherpa-onnx\nodejs-addon-examples\操作手册.md`
- FFmpeg 路径: `D:\MyProjects\c_projects\sherpa-onnx\ffmpeg\bin\`
- Whisper 模型: `D:\MyProjects\c_projects\sherpa-onnx\all_models\sherpa-onnx-whisper-tiny.en\`
- VAD 模型: `D:\MyProjects\c_projects\sherpa-onnx\all_models\silero_vad.onnx`

## 使用流程

### 步骤 1: 扫描视频文件
```bash
node scan-videos.js
```
扫描 `input/` 目录下的视频文件，生成 `output/video-list.json` 配置文件

### 步骤 2: 批量转换视频为音频
```bash
node batch-convert.js
```
根据配置文件批量转换视频为 WAV 格式音频，输出到 `output/audio/`

### 步骤 3: 批量识别音频
```bash
node transcribe-audio.js
```
使用 VAD + Whisper 识别音频，输出转录结果到 `output/transcription/`

### 步骤 4: 复制并处理转录文件
```bash
cd screenshot-scripts
node copy-to-transcription2.js
```
复制转录文件到 `output/transcription2/`，并删除包含 "ready" 的 segment 及其前面的所有内容

### 步骤 5: 生成视频截图
```bash
cd screenshot-scripts
node generate-screenshots.js
```
根据 `output/transcription2/` 中的转录结果，生成视频截图到 `output/screenshots/`