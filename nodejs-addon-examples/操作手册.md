# Sherpa-ONNX Node.js 语音识别操作手册

## 一、环境准备

### 1.1 系统要求
- Windows 10/11
- Node.js >= 16
- PowerShell

### 1.2 安装依赖
```powershell
cd D:\MyProjects\c_projects\sherpa-onnx\nodejs-addon-examples
npm install
```

---

## 二、模型文件准备

### 2.1 创建模型目录
```powershell
mkdir D:\MyProjects\c_projects\sherpa-onnx\all_models
```

### 2.2 下载所需模型

#### 1) Whisper 英文模型 (必须)
```powershell
cd D:\MyProjects\c_projects\sherpa-onnx\all_models
wget https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-whisper-tiny.en.tar.bz2

# 解压
tar xvf sherpa-onnx-whisper-tiny.en.tar.bz2
```

#### 2) VAD 模型 (长音频需要)
```powershell
cd D:\MyProjects\c_projects\sherpa-onnx\all_models
wget https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx
```

#### 3) 中英双语模型 (可选)
```powershell
cd D:\MyProjects\c_projects\sherpa-onnx\all_models
wget https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20.tar.bz2

# 解压
tar xvf sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20.tar.bz2
```

---

## 三、音频格式转换

### 3.1 安装 ffmpeg
下载 ffmpeg 并添加到 PATH，或使用：
```powershell
D:\MyProjects\c_projects\sherpa-onnx\ffmpeg\bin\ffmpeg.exe
```

### 3.2 MP3 转 WAV (16kHz, 16-bit, 单声道)
```powershell
D:\MyProjects\c_projects\sherpa-onnx\ffmpeg\bin\ffmpeg.exe `
    -i "输入音频.mp3" `
    -ar 16000 -ac 1 -sample_fmt s16 `
    "输出音频.wav"
```

---

## 四、语音识别

### 4.1 短音频 (<30秒) - 直接使用 Whisper

**文件**: `test_whisper_yd.js`

**修改音频路径**:
```javascript
const waveFilename = 'D:/你的/音频路径.wav';
```

**运行**:
```powershell
cd D:\MyProjects\c_projects\sherpa-onnx\nodejs-addon-examples
node .\test_whisper_yd.js
```

**输出**: 
- 控制台显示结果
- 结果保存到 `transcription_whisper_result.txt`

---

### 4.2 长音频 (>30秒) - VAD + Whisper

**文件**: `test_vad_with_non_streaming_asr_whisper_yd.js`

**修改音频路径**:
```javascript
const waveFilename = 'D:/你的/音频路径.wav';
```

**运行**:
```powershell
cd D:\MyProjects\c_projects\sherpa-onnx\nodejs-addon-examples
node .\test_vad_with_non_streaming_asr_whisper_yd.js
```

**输出**:
- 控制台显示分段结果（带时间戳）
- 结果保存到 `transcription_vad_whisper_result.txt`

---

### 4.3 流式识别 - 中英双语模型

**文件**: `test_asr_streaming_transducer_yd.js`

**适用场景**:
- 实时语音识别
- 中英混合内容
- 低延迟要求

**运行**:
```powershell
cd D:\MyProjects\c_projects\sherpa-onnx\nodejs-addon-examples
node .\test_asr_streaming_transducer_yd.js
```

---

## 五、模型选择指南

| 场景 | 推荐模型 | 特点 |
|------|---------|------|
| 纯英文音频 | Whisper | 准确率高，支持标点 |
| 中文/中英混合 | Zipformer | 流式识别，低延迟 |
| 长音频 (>30秒) | VAD + Whisper | 分段处理，完整识别 |
| 实时麦克风输入 | 流式 Zipformer | 实时输出 |

---

## 六、常见问题

### Q1: 报错 "Cannot find module 'sherpa-onnx-node'"
**解决**: 运行 `npm install`

### Q2: Whisper 只识别了前30秒
**解决**: 使用 `test_vad_with_non_streaming_asr_whisper_yd.js` 进行 VAD 分段处理

### Q3: 识别准确率不高
**解决**: 
- 确保音频清晰，背景噪音小
- 选择与语言匹配的模型（英文用 Whisper，中文用 Zipformer）
- 检查音频采样率是否为 16kHz

### Q4: 模型文件找不到
**解决**: 使用绝对路径，或检查模型是否已解压

---

## 七、文件清单

```
nodejs-addon-examples/
├── test_whisper_yd.js                          # Whisper 短音频识别
├── test_vad_with_non_streaming_asr_whisper_yd.js  # VAD+Whisper 长音频识别
├── test_asr_streaming_transducer_yd.js         # 流式中英双语识别
├── transcription_whisper_result.txt            # Whisper 输出结果
├── transcription_vad_whisper_result.txt        # VAD+Whisper 输出结果
└── transcription_result.txt                    # 流式模型输出结果

all_models/
├── sherpa-onnx-whisper-tiny.en/                # Whisper 模型
│   ├── tiny.en-encoder.int8.onnx
│   ├── tiny.en-decoder.int8.onnx
│   └── tiny.en-tokens.txt
├── silero_vad.onnx                             # VAD 模型
└── sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/  # 中英模型
```

---

## 八、示例输出

### Whisper 识别结果
```
音频文件: D:/.../video2_audio.wav
时长: 113.000 秒
处理时间: 9.808 秒
RTF: 0.087

=== 分段识别结果 ===
[1.16s - 2.09s]: lesson 2.
[2.85s - 4.14s]: repetition drill.
...

=== 完整文本 ===
lesson 2. repetition drill. look at number one. is this your pen? ...
```

---

**创建日期**: 2025-02-04  
**作者**: yd  
**版本**: 1.0
